# Generate a distribution package for PyPI.
# Publish the package on PyPI or TestPyPI.
# This reusable workflow uses the [pypi-publish](https://github.com/pypa/gh-action-pypi-publish) GitHub Action
# to publish the distribution package on either PyPI or TestPyPI, depending on the input.

name: '[Reusable]: Build'
on:
  workflow_call:
    inputs:
      config:
        description: Configuration as a JSON string.
        type: string
        required: true
    outputs:
      hashes:
        description: |
          Hash values of the generated build distributions.
          This is a JSON string representing an array of objects.
        value: ${{ jobs.hash-digest.outputs.hashes }}
jobs:
  pure:
    name: ${{ fromJSON(inputs.config).pkg.python.pure && 'Pure Python' || 'Source Distribution' }}
    runs-on: ubuntu-latest
    steps:
      - name: Repository Checkout
        uses: actions/checkout@v4
        with:
          repository: ${{ fromJSON(inputs.config).repository }}
          ref: ${{ fromJSON(inputs.config).ref }}
          fetch-depth: 0
          path: repo
      - name: Python Setup
        uses: actions/setup-python@v5
        with:
          python-version: 3.x
      - name: Environment Setup
        shell: bash
        run: |
          echo "::group::Requirements Installation"
          python -m pip install --upgrade pip build twine versioningit readme-renderer[md]
          echo "::endgroup::"
          echo "::group::Environment Overview"
          python3 -c "import sys; print(sys.version)"
          python3 -m pip list
          echo "::endgroup::"
      - name: Build
        shell: bash
        id: build
        env:
          PURE_PYTHON: ${{ fromJSON(inputs.config).pkg.python.pure }}
          PKG_PATH: repo/${{ fromJSON(inputs.config).pkg.path.root }}
          VERSIONINGIT_LOG_LEVEL: DEBUG  # https://versioningit.readthedocs.io/en/stable/configuration.html#log-level-environment-variable
        run: |
          echo "::group::Latest Git Tag"
          git -C repo describe || true
          echo "::endgroup::"

          echo "::group::Versioning"
          VERSION=$(versioningit $PKG_PATH --verbose)
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
          echo "::endgroup::"

          echo "::group::Package Directory Overview"
          ls -la "$PKG_PATH"
          echo "::endgroup::"

          echo "::group::Package Files Overview"
          find "$PKG_PATH" -ls
          echo "::endgroup::"

          if $PURE_PYTHON; then
            echo "::group::Source & Build Distribution"
            python -m build $PKG_PATH --outdir ./dist --verbose
            echo "::endgroup::"
          else
            echo "::group::Source Distribution"
            python -m build $PKG_PATH --outdir ./dist --sdist --verbose
            echo "::endgroup::"
          fi
      - name: PyPI README Check
        if: fromJSON(inputs.config).pkg.readme
        # Note:
        #    `twine check` (https://twine.readthedocs.io/en/stable/#twine-check) only works for
        #    reStructuredText (reST) READMEs; it always passes for Markdown content
        #    (cf. `twine.commands.check._RENDERERS` (https://github.com/pypa/twine/blob/4f7cd66fa1ceba7f8de5230d3d4ebea0787f17e5/twine/commands/check.py#L32-L37))
        #    and thus cannot be used to validate Markdown.
        #    It is used here only to check the existence of the README file in the built distributions.
        # Refs:
        #    https://twine.readthedocs.io/en/stable/#twine-check
        #    https://packaging.python.org/en/latest/guides/making-a-pypi-friendly-readme/#validating-restructuredtext-markup
        run: twine check ./dist/*
      - name: PyPI README Render
        if: fromJSON(inputs.config).pkg.readme.file
        shell: bash
        run: >-
          python -m readme_renderer
          'repo/${{ fromJSON(inputs.config).pkg.readme.file }}'
          --output ./README.html
      - name: Source Distribution Upload
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          path: ./dist/*.tar.gz
          name: ${{ fromJSON(inputs.config).artifact.sdist.name }}
          include-hidden-files: ${{ fromJSON(inputs.config).artifact.sdist.include-hidden }}
          retention-days: ${{ fromJSON(inputs.config).artifact.sdist.retention-days }}
      - name: Binary Distribution Upload
        if: ${{ !cancelled() && fromJSON(inputs.config).pkg.python.pure }}
        uses: actions/upload-artifact@v4
        with:
          path: ./dist/*.whl
          name: ${{ fromJSON(inputs.config).artifact.wheel.name }}
          include-hidden-files: ${{ fromJSON(inputs.config).artifact.wheel.include-hidden }}
          retention-days: ${{ fromJSON(inputs.config).artifact.wheel.retention-days }}
      - name: ReadMe Upload
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          path: ./README.html
          name: ${{ fromJSON(inputs.config).artifact.readme.name }}
          include-hidden-files: ${{ fromJSON(inputs.config).artifact.readme.include-hidden }}
          retention-days: ${{ fromJSON(inputs.config).artifact.readme.retention-days }}
  native:
    name: Binary Distribution | ${{ matrix.build.os.name }}
    if: ${{ !fromJSON(inputs.config).pkg.python.pure }}
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        build: ${{ fromJSON(inputs.config).cibw }}
    steps:
      - name: Repository Checkout
        uses: actions/checkout@v4
        with:
          repository: ${{ fromJSON(inputs.config).repository }}
          fetch-depth: 0
          ref: ${{ fromJSON(inputs.config).ref }}
          path: repo
      - name: Build
        # https://cibuildwheel.readthedocs.io/en/stable/
        # https://github.com/pypa/cibuildwheel
        uses: pypa/cibuildwheel@v2.22
        with:
          package-dir: ./repo/${{ fromJSON(inputs.config).pkg.path.root }}
          output-dir: ./dist
        env:
          CIBW_BUILD: ${{ matrix.python }}-${{ matrix.platform }}
          CIBW_BUILD_VERBOSITY: 2
      - name: Build Upload
        uses: actions/upload-artifact@v4
        with:
          path: ./dist
          name: ${{ matrix.artifact.wheel.name }}
          include-hidden-files: ${{ matrix.artifact.wheel.include-hidden }}
          retention-days: ${{ matrix.artifact.wheel.retention-days }}
  conda:
    name: Conda Distribution | ${{ matrix.task.os.name }}
    runs-on: ${{ matrix.task.os.runner }}
    strategy:
      fail-fast: false
      matrix:
        task: ${{ fromJSON(inputs.config).conda-builds }}
    defaults:
      run:
        shell: bash -el {0}
    steps:
      - name: Repository Checkout
        uses: actions/checkout@v4
        with:
          repository: ${{ fromJSON(inputs.config).repository }}
          fetch-depth: 0
          ref: ${{ fromJSON(inputs.config).ref }}
          path: repo
      - name: Miniconda Setup
        uses: conda-incubator/setup-miniconda@v3
        with:
          channels: ${{ fromJSON(inputs.config).conda-channels }}
          auto-activate-base: true
          activate-environment: ""
          miniconda-version: latest
          conda-build-version: '>=24.11'
      - name: Environment Setup
        run: |
          mkdir dist
          echo "::group::Requirements Installation"
          conda install versioningit
          echo "::endgroup::"
          echo "::group::Environment Overview"
          conda list
          echo "::endgroup::"
          echo "::group::Conda Info"
          conda info
          echo "::endgroup::"
      - name: Versioning
        id: version
        env:
          PKG_PATH: repo/${{ fromJSON(inputs.config).pkg.path.root }}
        run: |
          VERSION=$(versioningit $PKG_PATH --verbose)
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
      - name: Build
        env:
          PKG_FULL_VERSION: ${{ steps.version.outputs.version }}
        run: >-
          conda build repo/${{ fromJSON(inputs.config).conda-recipe-path }}
          --python ${{ matrix.task.python }}
          --package-format conda
          --output-folder dist
          --stats-file dist/build-stats.json
          --verify
          --keep-going
          --debug
          --no-anaconda-upload
      - name: Build Upload
        uses: actions/upload-artifact@v4
        with:
          path: ./dist
          name: ${{ matrix.task.artifact.name }}
          include-hidden-files: ${{ matrix.task.artifact.include-hidden }}
          retention-days: ${{ matrix.task.artifact.retention-days }}
  wheel-merge:
    name: Artifact Merge
    if: ${{ !cancelled() }}
    needs: [ pure, native, conda ]
    runs-on: ubuntu-latest
    steps:
      - name: Wheels
        uses: actions/upload-artifact/merge@v4
        if: ${{ fromJSON(inputs.config).artifact.wheel.merge }}
        with:
          name: ${{ fromJSON(inputs.config).artifact.wheel.merge.name }}
          pattern: ${{ fromJSON(inputs.config).artifact.wheel.merge.pattern }}
          include-hidden-files: ${{ fromJSON(inputs.config).artifact.wheel.include-hidden }}
          retention-days: ${{ fromJSON(inputs.config).artifact.wheel.retention-days }}
          separate-directories: 'false'
          delete-merged: 'true'
      - name: Conda Dists
        uses: actions/upload-artifact/merge@v4
        if: ${{ !cancelled() && fromJSON(inputs.config).artifact.conda.merge }}
        with:
          name: ${{ fromJSON(inputs.config).artifact.conda.merge.name }}
          pattern: ${{ fromJSON(inputs.config).artifact.conda.merge.pattern }}
          include-hidden-files: ${{ fromJSON(inputs.config).artifact.conda.include-hidden }}
          retention-days: ${{ fromJSON(inputs.config).artifact.conda.retention-days }}
          separate-directories: 'true'
          delete-merged: 'true'
  hash-digest:
    name: Hash Digest
    if: ${{ !cancelled() }}
    needs: [ wheel-merge ]
    runs-on: ubuntu-latest
    outputs:
      hashes: ${{ steps.hash.outputs.hashes }}
    steps:
      - name: Source Distribution Download
        uses: actions/download-artifact@v4
        with:
          name: ${{ fromJSON(inputs.config).artifact.sdist.name }}
          path: dists/sdist
      - name: Binary Distribution Download
        uses: actions/download-artifact@v4
        with:
          name: ${{ fromJSON(inputs.config).artifact.wheel.merge.name }}
          pattern: ${{ fromJSON(inputs.config).artifact.wheel.merge.pattern }}
          path: dists/wheels
          merge-multiple: 'true'
      - name: Conda Distribution Download
        uses: actions/download-artifact@v4
        with:
          name: ${{ fromJSON(inputs.config).artifact.conda.merge.name }}
          pattern: ${{ fromJSON(inputs.config).artifact.conda.merge.pattern }}
          path: dists/conda
          merge-multiple: 'true'
      - name: File Overview
        run: tree
      - name: Hash Generation
        id: hash
        run: |
          directory="dists"
          hashes="["
          while IFS= read -r -d '' file; do
              filename=$(basename "$file")
              md5=$(openssl dgst -md5 "$file" | awk '{print $NF}')
              sha1=$(openssl dgst -sha1 "$file" | awk '{print $NF}')
              sha256=$(openssl dgst -sha256 "$file" | awk '{print $NF}')
              hashes="$hashes{\"filename\":\"$filename\",\"md5\":\"$md5\",\"sha1\":\"$sha1\",\"sha256\":\"$sha256\"},"
          done < <(find "$directory" -type f \( -name "*.tar.gz" -o -name "*.whl" -o -name "*.conda" \) -print0)
          # Remove trailing comma and close the JSON array
          hashes="${hashes%,}]"
          # Output the JSON array
          echo "Hashes: $hashes"
          echo "hashes=$hashes" >> $GITHUB_OUTPUT
